#mono Linie mit viel Kommentare 
"""
Bewegungsspuren (Trails) von Personen im Kamerabild mit YOLOv8 tracken und
als "Neon-/Glow-Linien" mit Farbverlauf rendern.

Kernideen:
- YOLOv8 liefert pro Person eine Track-ID + Bounding Box. Aus der Box nehmen wir den Mittelpunkt als Spurpunkt.
- Wir speichern pro ID eine Liste von Punkten (Trail) und zeichnen sie segmentweise.
- Für den Neon-Look werden pro Segment drei Linien übereinander gerendert:
    1) breite, halbtransparente "Glow"-Linie
    2) mittlere, kräftigere Linie
    3) dünne, scharfe Kernlinie
- Zusätzlich färben wir die Segmente über die Trail-Länge: ältere Punkte heller, aktuelle Spitze dunkler.

Wichtige Stellschrauben (s.u. auch im Code markiert):
- fade_strength: Wie schnell "verblasst" die alte Spur in Richtung Hintergrund.
- smoothing_factor: Wie stark die Spur geglättet wird (träges Nachlaufen).
- max_track_length: Wie lang die Spur ist (Anzahl Punkte).
- thickness_* und alpha_*: Dicke und Intensität der drei Linienlagen.
- brightness_offset: Wie stark sich "hell" und "dunkel" im Verlauf unterscheiden.
"""

import cv2
from ultralytics import YOLO
import numpy as np
import random

# =========================
# ░ Parameter / Look-Setup ░
# =========================

# Wie schnell die Spur in den Hintergrund (weiß) verblasst:
#  - nahe 1.0  => Spur bleibt lange sichtbar (langsam)
#  - kleiner   => Spur verschwindet schneller (schnell)
fade_strength = 0.97

# Maximale Trail-Länge pro Person (Anzahl gespeicherter Punkte).
#  - größer  => längere Spur, mehr Zeichenaufwand
#  - kleiner => kürzere Spur, weniger Zeichenaufwand
max_track_length = 40

# Glättung der Punkte (Low-Pass-Filter):
#  - 0.0     => keine Glättung, direkter, aber zappeliger
#  - 0.3     => moderat glatt
#  - 0.5+    => sehr weich, aber "träge"
smoothing_factor = 0.3

# Helligkeits-Variation entlang des Trails (Verlauf):
#  - Ältester Punkt = heller, neuester Punkt = dunkler
#  - Erhöhe/erniedrige, um den Kontrast des Verlaufs zu ändern
brightness_offset = 80  # in BGR-Werten; 80 ist ein deutlicher, aber noch natürlicher Unterschied

# Neon/Glow-Stil: Dicken der drei "Lagen"
thickness_glow   = 12  # äußerer, weicher Schein
thickness_mid    = 6   # mittlere, kräftige Linie
thickness_core   = 2   # dünner, scharfer Kern

# Intensität (Alpha) der Blendings pro Lage (0..1):
#  - höheres Overlay-Alpha => stärkere Wirkung der jeweiligen Lage
alpha_glow = 0.20
alpha_mid  = 0.50
# Für die Kernlinie zeichnen wir ohne zusätzliches Blending (volle Deckkraft auf dem Trail-Layer)


# =================
# ░ YOLO vorbereit. ░
# =================

# YOLOv8 Modell laden:
# - "yolov8n.pt" = Nano (schnell, weniger präzise).
# - Größere Modelle (s/m/l/x) = genauer, aber langsamer.
model = YOLO("yolov8n.pt")

# Videoquelle öffnen (0: interne, 1: externe Kamera usw.)
cap = cv2.VideoCapture(0)
if not cap.isOpened():
    print("Fehler: Kamera oder Video konnte nicht geöffnet werden.")
    exit()

# Trail-Layer (wird jede Schleife aktualisiert)
# - Wir zeichnen NICHT direkt aufs Kamerabild, sondern auf eine "Leinwand"
# - Hintergrund ist weiß (255), siehe Initialisierung unten
trail_layer = None

# Speicherung der Trails und Farben pro Track-ID
tracks = {}     # dict: {track_id: [(x,y), ...]}
id_colors = {}  # dict: {track_id: (B,G,R)}  # OpenCV nutzt BGR!


def get_color_for_id(track_id: int):
    """
    Weise jeder ID eine feste Grundfarbe zu.
    - Random mit Seed=track_id => gleiche Person ⇒ gleiche Farbe über Zeit.
    - BGR-Werte in Bereich [100..255], damit es hell/leuchtend wirkt.
    """
    if track_id not in id_colors:
        rng = random.Random(track_id)
        color = (
            rng.randint(100, 255),  # Blau
            rng.randint(100, 255),  # Grün
            rng.randint(100, 255)   # Rot
        )
        id_colors[track_id] = color
    return id_colors[track_id]


def smooth_point(new_point, last_point, factor=0.3):
    """
    Exponentielle Glättung der Punktbewegung (Low-Pass).
    - factor groß   => neue Punkte haben mehr Gewicht (weicher/ träger)
    - factor klein  => folgt "schneller"/direkter der Bewegung
    """
    if last_point is None:
        return new_point
    x = int(last_point[0] * (1 - factor) + new_point[0] * factor)
    y = int(last_point[1] * (1 - factor) + new_point[1] * factor)
    return (x, y)


# ==========================
# ░ Fenster-/Anzeige-Setup ░
# ==========================

window_name = "WKD Summercamp 2025 ... Daniel, Giuliana, Jenny, Lea"
cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
cv2.setWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)

# Zielauflösung fürs Display (kannst du anpassen; Rendering skaliert dorthin)
screen_res = (1920, 1080)


# ============
# ░ Main-Loop ░
# ============
while True:
    ret, frame = cap.read()
    if not ret:
        print("Fehler: Frame konnte nicht gelesen werden.")
        break

    # Kamera spiegeln (wie Spiegel): Links/Rechts vertauscht,
    # fühlt sich für Interaktion natürlicher an.
    frame = cv2.flip(frame, 1)

    h, w, _ = frame.shape

    # Trail-Layer beim ersten Durchlauf anlegen:
    # - Weißer Hintergrund => 255
    #   (Wenn du schwarzen Hintergrund willst: np.zeros_like(frame, dtype=np.uint8))
    if trail_layer is None:
        trail_layer = np.ones_like(frame, dtype=np.uint8) * 255

    # YOLO-Tracking (persist=True behält IDs über Frames hinweg bei)
    # - result.boxes enthält u.a. xyxy (BBox), cls (Klasse), id (Track-ID)
    results = model.track(frame, persist=True, verbose=False)
    result = results[0]

    # "Verblassen" der alten Spur:
    # - addWeighted mischt den aktuellen Trail-Layer mit einer weißen Fläche.
    # - fade_strength nahe 1.0 => alter Trail dominiert (langsames Ausblenden)
    # - (1 - fade_strength) => Anteil Weiß (Hintergrund)
    trail_layer = cv2.addWeighted(
        trail_layer,                 # Bild A
        fade_strength,               # Gewicht A
        np.ones_like(trail_layer) * 255,  # Bild B (weiß)
        1 - fade_strength,           # Gewicht B
        0                            # Gamma (Bias)
    )

    # Alle erkannten Objekte durchgehen (falls vorhanden)
    # - Wir filtern auf Klasse 0 (COCO: "person")
    if hasattr(result, "boxes") and result.boxes.id is not None:
        for box, cls, track_id in zip(result.boxes.xyxy, result.boxes.cls, result.boxes.id):
            if int(cls) == 0:  # nur Personen
                x1, y1, x2, y2 = map(int, box)
                # Mittelpunkt der BBox als "Spurpunkt"
                cx = (x1 + x2) // 2
                cy = (y1 + y2) // 2

                tid = int(track_id)
                if tid not in tracks:
                    tracks[tid] = []

                # Glätten gegen Zappeln
                last_point = tracks[tid][-1] if tracks[tid] else None
                smooth_pt = smooth_point((cx, cy), last_point, factor=smoothing_factor)

                # Punkt zur Spur hinzufügen und ggf. kürzen
                tracks[tid].append(smooth_pt)
                if len(tracks[tid]) > max_track_length:
                    tracks[tid].pop(0)

                # ============
                # Rendering: Segmentweise mit Farbverlauf + Glow
                # ============

                # Grundfarbe (BGR) der Person
                base_color = np.array(get_color_for_id(tid), dtype=np.int32)
                num_points = len(tracks[tid])

                # Nur zeichnen, wenn es mind. 2 Punkte gibt (sonst kein Segment)
                if num_points >= 2:
                    # "hellere" und "dunklere" Variante der Grundfarbe erzeugen
                    # (np.clip, damit BGR im Bereich [0..255] bleibt)
                    bright = np.clip(base_color + brightness_offset, 0, 255)
                    dark   = np.clip(base_color - brightness_offset, 0, 255)

                    for i in range(num_points - 1):
                        pt1 = tracks[tid][i]
                        pt2 = tracks[tid][i + 1]

                        # Interpolationsfaktor entlang der Spur:
                        #  - i = 0 (ältester Punkt)  => t ~ 0  => Farbe ~ bright
                        #  - i = letzter Index       => t ~ 1  => Farbe ~ dark
                        t = i / (num_points - 1)

                        # Lineare Interpolation zwischen "bright" und "dark"
                        color = (bright * (1 - t) + dark * t).astype(np.uint8).tolist()

                        # --- Lage 1: Glow (breit, halbtransparent) ---
                        overlay = trail_layer.copy()
                        cv2.line(overlay, pt1, pt2, color, thickness=thickness_glow, lineType=cv2.LINE_AA)
                        trail_layer = cv2.addWeighted(overlay, alpha_glow, trail_layer, 1 - alpha_glow, 0)

                        # --- Lage 2: mittlere Linie (kräftiger) ---
                        overlay = trail_layer.copy()
                        cv2.line(overlay, pt1, pt2, color, thickness=thickness_mid, lineType=cv2.LINE_AA)
                        trail_layer = cv2.addWeighted(overlay, alpha_mid, trail_layer, 1 - alpha_mid, 0)

                        # --- Lage 3: Kernlinie (scharf, dünn, volle Deckkraft) ---
                        cv2.line(trail_layer, pt1, pt2, color, thickness=thickness_core, lineType=cv2.LINE_AA)

    # Für die Anzeige auf Zielauflösung skalieren (reines Display-Thema)
    frame_resized = cv2.resize(trail_layer, screen_res, interpolation=cv2.INTER_LINEAR)
    cv2.imshow(window_name, frame_resized)

    # Tastaturabfrage:
    # - 'q' beendet das Programm
    key = cv2.waitKey(1) & 0xFF
    if key == ord('q'):
        break

# Aufräumen
cap.release()
cv2.destroyAllWindows()
